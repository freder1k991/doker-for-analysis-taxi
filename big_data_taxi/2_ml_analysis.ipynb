{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00186d-eee4-425b-8c78-4b3f05310e0b",
   "metadata": {},
   "source": [
    "# Тетрадка с ML моделями\n",
    "**Установка основных библиотек и spark сессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed8c3a-50e8-437f-aa24-b1c124989dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f659cd03-e988-4906-8efe-435869642118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#visual\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 480)\n",
    "\n",
    "from matplotlib import rcParams \n",
    "sns.set(context='notebook', style='whitegrid', rc={'figure.figsize': (18,4)})\n",
    "rcParams['figure.figsize'] = 18,4\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#format\n",
    "from pyspark.sql.functions import (to_timestamp, date_trunc, month, \n",
    "                                   year, dayofweek, avg, hour, \n",
    "                                   dayofmonth, lag, expr,\n",
    "                                   sin, cos, lit)\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "# setting random seed for notebook reproducability\n",
    "rnd_seed=23\n",
    "np.random.seed=rnd_seed \n",
    "np.random.set_state=rnd_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3a922c-453e-4ca1-8df6-9cb7ddb4a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_MASTER_IP = '172.18.0.2'\n",
    "\n",
    "#spark = SparkSession.builder.appName(\"pyspark-taxi-forecasting\") \\\n",
    "#    .master(f\"spark://{SPARK_MASTER_IP}:7077\") \\\n",
    "#    .config(\"spark.executor.cores\", 1) \\\n",
    "#    .config(\"spark.task.cpus\", 1) \\\n",
    "#    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"pyspark-taxi-forecasting\") \\\n",
    "        .config(\"spark.executor.cores\", 1) \\\n",
    "        .config(\"spark.task.cpus\", 1) \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config('spark.driver.bindAddress','localhost') \\\n",
    "        .config('spark.ui.port', 4040) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd693888-5188-4767-9796-a2dbf4a09dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-taxi-forecasting</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcfd93c6c50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.getActiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fb7516-5fda-4b2e-a47d-1fa0dc04f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e67667-82a0-4c47-b210-72f8123b77e7",
   "metadata": {},
   "source": [
    "# Основные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eea55ce-c30c-47d1-892d-ee595c338ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#группируем по 1 часу и районам\n",
    "def tables_area(df):\n",
    "    df.createOrReplaceTempView(\"table\")\n",
    "\n",
    "    tables_dict = {}\n",
    "    \n",
    "    for i in range(1, 78):\n",
    "        name = i\n",
    "        tab = spark.sql(f\"\"\"\n",
    "            select datetime, \n",
    "                   sum(count_1h) as count_1h\n",
    "            from (select\n",
    "                        date_format(datetime, \"yyyy-MM-dd HH:00:00\") as datetime,\n",
    "                        count(*) as count_1h\n",
    "                              from (select id, datetime from table where area = {i}) as ar\n",
    "                    GROUP BY datetime\n",
    "                    ORDER BY datetime) as t\n",
    "            GROUP BY datetime\n",
    "            ORDER BY datetime\n",
    "                        \"\"\")\n",
    "        # Сохраняем таблицу в словаре с использованием имени как ключа\n",
    "        tables_dict[name] = tab\n",
    "    \n",
    "    return tables_dict  # Возвращаем словарь с таблицами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0642cf-fa19-44d4-ae47-e9a2fcbb6846",
   "metadata": {},
   "source": [
    "Думаю, на этом моменте нужно уделить по больше внимания. ДАнная функция генерит временные признаки, лаг количества заказов и среднее кол-во заказов за определенный диапазон. \n",
    "\r\n",
    "Так же эта функция поддерживает как словарь, так и обычную таблицу. + Дописал отдельный исход действий для дополнительной тестовой таблицы(третья тестовая таблица). Правда не совсем понял из каких значений делать для нее лаги.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "590739f4-36f6-4bd1-860e-538e60557d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сознадие признаков\n",
    "\n",
    "def features_area(data, max_lag, rolling_mean):\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "    \n",
    "        for i in range(1, 78):\n",
    "            #год\n",
    "            #sdf = sdf.withColumn(\"Year\", year(\"datetime\"))#спорно\n",
    "            #месяц\n",
    "            data[i] = data[i].withColumn(\"month\", month(\"datetime\"))\n",
    "            #день\n",
    "            data[i] = data[i].withColumn(\"day\", dayofmonth(\"datetime\"))\n",
    "            #день недели\n",
    "            data[i] = data[i].withColumn(\"day_week\", dayofweek(\"datetime\"))\n",
    "            #час \n",
    "            data[i] = data[i].withColumn(\"hour\", hour(\"datetime\"))\n",
    "\n",
    "            #lag\n",
    "            for m in range(1, max_lag+1):\n",
    "                name = 'lag_' + str(m)\n",
    "                # Определяем окно (порядок сортировки) для использования lag\n",
    "                window_spec = Window.orderBy(\"datetime\")\n",
    "                data[i] = data[i].withColumn(name, lag(\"count_1h\", m).over(window_spec))\n",
    "\n",
    "            # rolling mean\n",
    "            window_spec = Window.orderBy(\"datetime\")\n",
    "            data[i] = data[i].withColumn(\"rolling_mean\", avg(\"count_1h\").over(window_spec.rowsBetween(-rolling_mean-1, -1)))\n",
    "\n",
    "            #удаление пропусков\n",
    "            data[i] = data[i].na.drop()\n",
    "        \n",
    "        return data\n",
    "\n",
    "    elif \"area\" in sdf_test.columns:\n",
    "        #месяц\n",
    "        data = data.withColumn(\"month\", month(\"datetime\"))\n",
    "            #день\n",
    "        data = data.withColumn(\"day\", dayofmonth(\"datetime\"))\n",
    "            #день недели\n",
    "        data = data.withColumn(\"day_week\", dayofweek(\"datetime\"))\n",
    "            #час \n",
    "        data = data.withColumn(\"hour\", hour(\"datetime\"))\n",
    "        \n",
    "        #пустой лаг\n",
    "        for i in range(1, max_lag+1):\n",
    "            lag_col_name = f\"lag_{i}\"\n",
    "            data = data.withColumn(lag_col_name, lit(0))\n",
    "        #mean как и таргет\n",
    "        data = data.withColumn(\"rolling_mean\", data.count_1h)\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        #год\n",
    "        #sdf = sdf.withColumn(\"Year\", year(\"datetime\"))#спорно\n",
    "        #месяц\n",
    "        data = data.withColumn(\"month\", month(\"datetime\"))\n",
    "        #день\n",
    "        data = data.withColumn(\"day\", dayofmonth(\"datetime\"))\n",
    "        #день недели\n",
    "        data = data.withColumn(\"day_week\", dayofweek(\"datetime\"))\n",
    "        #час \n",
    "        data = data.withColumn(\"hour\", hour(\"datetime\"))\n",
    "\n",
    "        #lag\n",
    "        for m in range(1, max_lag+1):\n",
    "            name = 'lag_' + str(m)\n",
    "            # Определяем окно (порядок сортировки) для использования lag\n",
    "            window_spec = Window.orderBy(\"datetime\")\n",
    "            data = data.withColumn(name, lag(\"count_1h\", m).over(window_spec))\n",
    "\n",
    "            # rolling mean\n",
    "            window_spec = Window.orderBy(\"datetime\")\n",
    "            data = data.withColumn(\"rolling_mean\", avg(\"count_1h\").over(window_spec.rowsBetween(-rolling_mean-1, -1)))\n",
    "\n",
    "            #удаление пропусков\n",
    "            data = data.na.drop()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d40815-fe31-4058-9876-f79c068dac33",
   "metadata": {},
   "source": [
    " Данная функция создана для разбиения данных на выборки и не происходило перемешивание. \r\n",
    "\r\n",
    "Тренировочная выборка составила 80 %, валидационная и тренировочная по 10 %\r\n",
    "\r\n",
    "Поддержи типвает словарь и обычную таблу.\r\n",
    "% \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83264dd-5dc9-4758-acb1-b53f3e220d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделение на 3 выборки \n",
    "def split(data):\n",
    "    #размеры \n",
    "    train_ratio = 0.8\n",
    "    validation_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    #создание 3 новых словарей \n",
    "    df_train = {}\n",
    "    df_validation = {}\n",
    "    df_test = {}\n",
    "    if isinstance(data, dict):\n",
    "        for i in range(1, 78):\n",
    "        \n",
    "            # Рассчитайте индексы для разделения данных\n",
    "            total_count = data[i].count()\n",
    "            train_split_index = int(total_count * train_ratio)\n",
    "            validation_split_index = int(total_count * (train_ratio + validation_ratio))\n",
    "\n",
    "            # Разделите данные на тренировочную, валидационную и тестовую выборки\n",
    "            df_train_1 = data[i].limit(train_split_index)\n",
    "            df_validation_1 = data[i].limit(validation_split_index).subtract(df_train_1)\n",
    "            df_test_1 = data[i].subtract(df_train_1).subtract(df_validation_1)\n",
    "\n",
    "            #добавление в словарь\n",
    "            df_train[i] = df_train_1\n",
    "            df_validation[i] = df_validation_1\n",
    "            df_test[i] = df_test_1\n",
    "        return df_train,df_validation,df_test\n",
    "\n",
    "    else:\n",
    "        # Рассчитайте индексы для разделения данных\n",
    "        total_count = data.count()\n",
    "        train_split_index = int(total_count * train_ratio)\n",
    "        validation_split_index = int(total_count * (train_ratio + validation_ratio))\n",
    "\n",
    "        # Разделите данные на тренировочную, валидационную и тестовую выборки\n",
    "        df_train_1 = data.limit(train_split_index)\n",
    "        df_validation_1 = data.limit(validation_split_index).subtract(df_train_1)\n",
    "        df_test_1 = data.subtract(df_train_1).subtract(df_validation_1)\n",
    "\n",
    "        #добавление в словарь\n",
    "        df_train = df_train_1\n",
    "        df_validation = df_validation_1\n",
    "        df_test = df_test_1\n",
    "        return df_train,df_validation,df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3e25f-ffa4-40a3-81dd-6bf78eb48576",
   "metadata": {},
   "source": [
    "Функция МАПЕ (Mean Absolute Percentage Error) рассчитывается вручную тк библиотеки подходящей не нашел. Она измеряет среднюю абсолютную процентную ошибку между фактическими и прогнозируемыми значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007fce74-9004-4435-b0e4-2832afa89b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-ция оценки МАПЕ\n",
    "def mape(df, label_col, prediction_col):  #target_pred, \n",
    "    \n",
    "    # Добавьте новую колонку с абсолютной разницей между предсказаниями и фактическими значениями\n",
    "    target_pred_mape = df.withColumn(\"abs_error\", expr(f\"abs({label_col} - {prediction_col})\"))\n",
    "\n",
    "    # Рассчитываем абсолютную процентную ошибку (MAPE) для каждой строки\n",
    "    df_with_mape = target_pred_mape.withColumn(\"mape\", (expr(\"abs_error\") / col(label_col)) * 100)\n",
    "\n",
    "    # Рассчитываем среднюю MAPE\n",
    "    mape = df_with_mape.selectExpr(\"avg(mape) as average_mape\").collect()[0][0]\n",
    "\n",
    "    return  mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71016b0-881e-47c0-9da5-e5010a83aff6",
   "metadata": {},
   "source": [
    "Кодирую временные признаки отдельно чтобы избежать перепада между 23 и 0 часами. Если кодировать обычным методом, то модель, которая будет обучатся на этих признаках будет воспринимать 23 ч. как большую переменную, а 0 ч. как меньшую. Поэтому все временные данные кодирую в виде sin и cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ca19a1-f1ab-4371-8160-f6070b96bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодирование временных признаков\n",
    "def encode(data, col_nam, max_val):\n",
    "    nam_sim = col_nam + '_sin'\n",
    "    nam_cos = col_nam + '_cos'\n",
    "    if isinstance(data, dict):\n",
    "        for i in range(1, 78):\n",
    "                \n",
    "            data[i] = data[i].withColumn(nam_sim, sin(2 * 3.14159 * col(col_nam) / max_val))\n",
    "            feature_time_new.append(nam_sim)\n",
    "        \n",
    "            data[i] = data[i].withColumn(nam_cos, cos(2 * 3.14159 * col(col_nam) / max_val))\n",
    "            feature_time_new.append(nam_cos)\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        data = data.withColumn(nam_sim, sin(2 * 3.14159 * col(col_nam) / max_val))\n",
    "        feature_time_new.append(nam_sim)\n",
    "        \n",
    "        data = data.withColumn(nam_cos, cos(2 * 3.14159 * col(col_nam) / max_val))\n",
    "        feature_time_new.append(nam_cos)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81cbf4-432d-4a7f-b378-d7b78776b60f",
   "metadata": {},
   "source": [
    "# общий запрос запуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fd0c2a-6f10-448c-a0c1-7f0b713f2161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, datetime: timestamp, area: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_22 = \"fails/Taxi_Trips_-_2022.csv\"\n",
    "taxi_23 = \"fails/Taxi_Trips_-_2023.csv\"\n",
    "\n",
    "sdf_22 = spark.read.csv(path=taxi_22, header=True, inferSchema=True)\n",
    "#выбор столбцов {id аменить на другую фичу, нужна для caunt()}\n",
    "sdf_22 = sdf_22.select([\"Trip ID\", \"Trip Start Timestamp\", 'Pickup Community Area'])\n",
    "\n",
    "sdf_23 = spark.read.csv(path=taxi_23, header=True, inferSchema=True)\n",
    "#выбор столбцов {id аменить на другую фичу, нужна для caunt()}\n",
    "sdf_23 = sdf_23.select(['Trip ID', 'Trip Start Timestamp', 'Pickup Community Area'])\n",
    "\n",
    "sdf = sdf_22.union(sdf_23)\n",
    "sdf = sdf.withColumnRenamed(\"Trip Start Timestamp\", \"datetime\")\n",
    "sdf = sdf.withColumnRenamed(\"Pickup Community Area\", \"area\")\n",
    "sdf = sdf.withColumnRenamed(\"Trip ID\", \"id\")\n",
    "#изменение формата в столбце с датой и временем начала поездки  \n",
    "timestamp_format = \"MM/dd/yyyy hh:mm:ss a\"\n",
    "\n",
    "sdf = sdf.withColumn(\"datetime\", to_timestamp(\"datetime\", timestamp_format))\n",
    "\n",
    "sdf = sdf.na.drop()\n",
    "\n",
    "\n",
    "    #вырезаем данные которые нужно будет потом предсказать на лучшей модели\n",
    "lim = '2023-07-31 23:00'\n",
    "sdf = sdf.filter(F.to_timestamp(F.col('datetime'), 'MM/dd/yyyy hh:mm:ss a')<lim)\n",
    "\n",
    "sdf.cache()\n",
    "#группировка по 1 часу\n",
    "table_areas = tables_area(sdf)\n",
    "#mime seria\n",
    "time = sdf.select('datetime').groupby(date_trunc('hour', 'datetime')).count()\\\n",
    "       .withColumnRenamed(\"date_trunc(hour, datetime)\", \"datetime\")\\\n",
    "       .orderBy('datetime')\\\n",
    "       .select('datetime')\n",
    "#заполнение недостающих часов 0\n",
    "for i in range(1, 78):\n",
    "    table_areas[i] = table_areas[i]\\\n",
    "                     .join(time, on='datetime', how='right_outer')\\\n",
    "                     .orderBy('datetime')\\\n",
    "                     .fillna(0)\n",
    "    table_areas[i].cache()\n",
    "                     #.write.csv(f'area_1_hours/{i}_area.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921cf26-d531-45ec-b975-ce89e6371fc9",
   "metadata": {},
   "source": [
    "# Обработка данных перед обучением \n",
    "Создаю признаки, кодирую временные и все остальные созданные признаки стандартизирую. Все фичи соединяю в единый вектор и выгружаю созданную таблицу, чтобы при перезапуске ядра не возвращается к этому процессу повторно. \r\n",
    "\r\n",
    "P.S. если кто-то будет это запускать когда-,то то нужно выбрать папку для выгрузки табл)ц.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3b0dc1-5038-4290-8d4c-067dc015ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#генерация признаков\n",
    "features_area(table_areas, 4, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30f945d-c68f-4970-8c69-aa0897d75911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняю всю таблицу\n",
    "#for i in range(1, 78):\n",
    "#    table_areas[i].write.parquet(f'arima/{i}_feature_area.parquet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9870ef-715f-4a82-8ca0-3f4f4e9a2aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#кодирование временных признаков \n",
    "feature_time_new = []\n",
    "feature_all = table_areas[1].drop('datetime','count_1h',\n",
    "                                   'month', 'day', \n",
    "                                   'day_week', 'hour'\n",
    "                                   ).columns\n",
    "#Кодируем месяцы\n",
    "encode(table_areas, 'month', 12);\n",
    "\n",
    "#Кодируем часы\n",
    "encode(table_areas, 'hour', 24);\n",
    "\n",
    "#Кодируем дни\n",
    "encode(table_areas, 'day', 31);\n",
    "\n",
    "#Кодируем день недели\n",
    "encode(table_areas, 'day_week', 7);\n",
    "\n",
    "#сохранение уникальных временных признаков\n",
    "feature_time_new = list(set(feature_time_new))\n",
    "feature_time_new.append('features_scaled');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86fb923b-374a-4a4b-9c0f-195d40685cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#стандартизация всех остальных признаков\n",
    "for i in range(1, 78):\n",
    "    #создание вектора\n",
    "    assembler = VectorAssembler(inputCols=feature_all, outputCol=\"features_no_time\")\n",
    "    table_areas[i] = assembler.transform(table_areas[i])\n",
    "\n",
    "    # Инициализируем `standardScaler`\n",
    "    standardScaler = StandardScaler(inputCol='features_no_time', outputCol=\"features_scaled\")\n",
    "    # Обучим \n",
    "    table_areas[i] = standardScaler.fit(table_areas[i]).transform(table_areas[i])\n",
    "\n",
    "    #создание общего вектора \n",
    "    assembler2 = VectorAssembler(inputCols=feature_time_new, outputCol=\"features_all\")\n",
    "    table_areas[i] = assembler2.transform(table_areas[i])\n",
    "\n",
    "    table_areas[i] = table_areas[i].select('datetime', \"count_1h\", \"features_all\")\n",
    "    \n",
    "    #сохраняю таблицу с временем, заказами и вектором признаков\n",
    "    #table_areas[i].write.parquet(f'area_1_hours/{i}_area.parquet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76a8822a-441e-4950-a236-8c7b0126786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_areas[2].printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac27d5-eabf-46f2-92c3-b8cafaaa3033",
   "metadata": {},
   "source": [
    "**Завершаю спарк сессию, и перезапускаю ее заново с обновлением ядра. Чтобы выгрузить все ненужное из кэша и освободить память.**\n",
    "\n",
    "Загружаю таблицы в новый словарь и все готово к обучению моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21adb7b1-c0b4-40e7-b591-d28e8b75070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#завершаем спарк сессию \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd25bc68-b695-4f2e-8a8f-92df30647aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#запускаем новую\n",
    "spark = SparkSession.builder.appName(\"pyspark-taxi-forecasting\") \\\n",
    "        .config(\"spark.executor.cores\", 1) \\\n",
    "        .config(\"spark.task.cpus\", 1) \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config('spark.driver.bindAddress','localhost') \\\n",
    "        .config('spark.ui.port', 4040) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17dfd6e4-8fd4-4f5a-89be-0c7966c50c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"datetime\", TimestampType(), nullable=False),\n",
    "    StructField(\"count_1h\", LongType(), nullable=False),\n",
    "    StructField(\"features_all\", VectorUDT(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eea7a34-026d-4c11-a3e3-0e34a3e19d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[datetime: timestamp, count_1h: bigint, features_all: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузки районо с диска \n",
    "dikt = {}\n",
    "for i in range(1, 78):\n",
    "    path_to_parquet_files = f'area_1_hours/{i}_area.parquet'\n",
    "    dikt[i] = spark.read.schema(schema).parquet(path_to_parquet_files)\n",
    "    dikt[i].cache();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14176e01-94e4-4499-9c02-9114b53dbfb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Модель линейной регрессии \r\n",
    "обучаю модель для каждого района по отдельности пытаюсь добиться самой лучшей метрик на валидационной выборкеи, а потом только делаю предсказание на тестовой выборк.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca5ab07-9972-49ac-b8bb-aaea09ab5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_validation, df_test = split(dikt)\n",
    "\n",
    "#задание параметров модели\n",
    "#предикт и таргет\n",
    "label_col = 'count_1h'\n",
    "prediction_col = 'pred_lr'\n",
    "features = 'features_all'\n",
    "#оценка качества модели\n",
    "mae_all_val = []\n",
    "mae_all_test = []\n",
    "\n",
    "mape_all_val = []\n",
    "mape_all_test = []\n",
    "\n",
    "models_lr = {}\n",
    "\n",
    "# Инициилизируем модель\n",
    "lr = (LinearRegression(featuresCol=features,\n",
    "                       labelCol=label_col, \n",
    "                       predictionCol=prediction_col, \n",
    "                       standardization=False,\n",
    "                       maxIter=100, \n",
    "                       regParam=0.001)) \n",
    "\n",
    "for i in range(1, 78):\n",
    "\n",
    "    # Обучиаем модель на данных\n",
    "    models_lr[i] = lr.fit(df_train[i])\n",
    "\n",
    "    #предсказание\n",
    "    df_validation[i] = models_lr[i].transform(df_validation[i])\n",
    "    #MAE\n",
    "    evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "    mae_val = format(evaluator.evaluate(df_validation[i]))\n",
    "    mae_all_val.append(float(mae_val))\n",
    "    #MAPE\n",
    "    result_val = mape(df_validation[i], label_col, prediction_col)\n",
    "    mape_all_val.append(result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d13f77fb-903b-4703-b1ce-37d93ef022d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Среднее МАЕ по всем районам:', 2.398187916830095)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Среднее МАРЕ по всем районам:', 54.696354021268846)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Среднее МАЕ по всем районам:', sum(mae_all_val)/len(mae_all_val)\n",
    "'Среднее МАРЕ по всем районам:', sum(mape_all_val)/len(mape_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3287363f-9b12-4cb3-b7f6-d421f1505fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#предсказание test \n",
    "for i in range(1, 78):\n",
    "     \n",
    "    df_test[i] = models_lr[i].transform(df_test[i])\n",
    "    #MAE\n",
    "    evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "    mae_test = format(evaluator.evaluate(df_test[i]))\n",
    "    mae_all_test.append(float(mae_test))\n",
    "    #MAPE\n",
    "    result_test = mape(df_validation[i], label_col, prediction_col)\n",
    "    mape_all_test.append(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db19b4d4-c882-4a7f-95ce-f052330d80b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Среднее МАЕ по всем районам на тестостовой выборкуе:', 2.3826978859408636)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Среднее МАРЕ по всем районам на тестостовой выборкуе:', 54.696354021268846)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Среднее МАЕ по всем районам на тестостовой выборкуе:', sum(mae_all_test)/len(mae_all_test)\n",
    "'Среднее МАРЕ по всем районам на тестостовой выборкуе:', sum(mape_all_test)/len(mape_all_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8648d0-f223-425d-970b-1655c29d0db5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Модель Линейной грегрессии на 1 \n",
    "обучал тестово для одного района, просто решил оставить на память) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b1ff5d-e2ea-403d-a059-8253052ddb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#table_areas[7].show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd8690e-dc9f-4b6a-8d63-e1ecae373037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#генерация признаков\n",
    "#table_areas[7] = features_area(table_areas[7], 4, 6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9981e413-ced4-4dd9-982b-d4c075d3c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодирование временных признаков \n",
    "#feature_time_new = []\n",
    "#feature_all = table_areas[7].drop('datetime','count_1h',\n",
    "#                                   'month', 'day', \n",
    "#                                   'day_week', 'hour'\n",
    "#                                   ).columns\n",
    "#Кодируем месяцы\n",
    "#table_areas[7] = encode(table_areas[7], 'month', 12);\n",
    "\n",
    "#Кодируем часы\n",
    "#table_areas[7] = encode(table_areas[7], 'hour', 24);\n",
    "\n",
    "#Кодируем дни\n",
    "#table_areas[7] =encode(table_areas[7], 'day', 31);\n",
    "\n",
    "#Кодируем день недели\n",
    "#table_areas[7] =encode(table_areas[7], 'day_week', 7);\n",
    "\n",
    "#сохранение уникальных временных признаков\n",
    "#feature_time_new = list(set(feature_time_new))\n",
    "#feature_time_new.append('features_scaled');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d998504-4df5-4c41-ae38-7d8cb01c2d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 район \n",
    "#создание вектора \n",
    "#assembler = VectorAssembler(inputCols=feature_all, outputCol=\"features_no_time\")\n",
    "#table_areas[7] = assembler.transform(table_areas[7])\n",
    "  # Инициализируем `standardScaler`\n",
    "#standardScaler = StandardScaler(inputCol='features_no_time', outputCol=\"features_scaled\")\n",
    "    # Обучим \n",
    "#table_areas[7] = standardScaler.fit(table_areas[7]).transform(table_areas[7])\n",
    "    #создание общего вектора \n",
    "#assembler2 = VectorAssembler(inputCols=feature_time_new, outputCol=\"features_all\")\n",
    "#table_areas[7] = assembler2.transform(table_areas[7])\n",
    "\n",
    "#table_areas[7] = table_areas[7].select('datetime', \"count_1h\", \"features_all\")\n",
    "    \n",
    "    #сохраняю таблицу с временем, заказами и вектором признаков\n",
    "#table_areas[6].write.parquet(f'area_1_hours/{i}_area.parquet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fec55dc-aca7-494a-bee8-7bb62a6321a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train, df_validation, df_test = split(table_areas[7])\n",
    "\n",
    "# Инициилизируем модель\n",
    "#задание параметров модели\n",
    "#предикт и таргет\n",
    "#label_col = 'count_1h'\n",
    "#prediction_col = 'pred_lr'\n",
    "#features = 'features_all'\n",
    "#оценка качества модели\n",
    "#mae_all_val = []\n",
    "#mae_all_test = []\n",
    "#mape_all_val = []\n",
    "#mape_all_test = []\n",
    "\n",
    "#models_lr = {}\n",
    "\n",
    "# Инициилизируем модель\n",
    "#lr = (LinearRegression(featuresCol=features,\n",
    "#                       labelCol=label_col, \n",
    "#                       predictionCol=prediction_col, \n",
    "#                       standardization=False,\n",
    "#                       maxIter=100, regParam=0.001))\n",
    "# Обучиаем модель на данных\n",
    "#models_lr = lr.fit(df_train)\n",
    "\n",
    "    #предсказание\n",
    "#df_validation = models_lr.transform(df_validation)\n",
    "    #MAE\n",
    "#evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "#mae_val = format(evaluator.evaluate(df_validation))\n",
    "#mae_all_val.append(float(mae_val))\n",
    "    #MAPE\n",
    "#result_val = mape(df_validation, label_col, prediction_col)\n",
    "#mape_all_val.append(result_val)\n",
    "\n",
    "#mae_all_val\n",
    "#mape_all_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff510cc8-4c2e-487e-a4f5-68882d2209f3",
   "metadata": {},
   "source": [
    "# Модель Деревья решений (Decision Trees) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbba118-8650-45e0-bd77-3a8ffdf10dd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Для 1 района "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d4253ce-415f-447f-856a-d8508ac6aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#генерация признаков\n",
    "#table_areas[7] = features_area(table_areas[7], 8, 3);\n",
    "\n",
    "\n",
    "#кодирование временных признаков \n",
    "#feature_time_new = []\n",
    "#feature_all = table_areas[7].drop('datetime','count_1h',\n",
    "                                   #'month', 'day', \n",
    "#                                   'day_week', \n",
    "#                                  'hour'\n",
    "#                                   ).columns\n",
    "#Кодируем месяцы\n",
    "#table_areas[7] = encode(table_areas[7], 'month', 12);\n",
    "\n",
    "#Кодируем часы\n",
    "#table_areas[7] = encode(table_areas[7], 'hour', 24);\n",
    "\n",
    "#Кодируем дни\n",
    "#table_areas[7] =encode(table_areas[7], 'day', 31);\n",
    "\n",
    "#Кодируем день недели\n",
    "#table_areas[7] =encode(table_areas[7], 'day_week', 7);\n",
    "\n",
    "#сохранение уникальных временных признаков\n",
    "#feature_time_new = list(set(feature_time_new))\n",
    "#feature_time_new.append('features_scaled');\n",
    "#1 район \n",
    "#создание вектора \n",
    "#assembler = VectorAssembler(inputCols=feature_all, outputCol=\"features_no_time\")\n",
    "##table_areas[7] = assembler.transform(table_areas[7])\n",
    "  # Инициализируем `standardScaler`\n",
    "#standardScaler = StandardScaler(inputCol='features_no_time', outputCol=\"features_scaled\")\n",
    "    # Обучим \n",
    "#table_areas[7] = standardScaler.fit(table_areas[7]).transform(table_areas[7])\n",
    "    #создание общего вектора \n",
    "#assembler2 = VectorAssembler(inputCols=feature_time_new, outputCol=\"features_all\")\n",
    "#table_areas[7] = assembler2.transform(table_areas[7])\n",
    "\n",
    "#table_areas[7] = table_areas[7].select('datetime', \"count_1h\", \"features_all\")\n",
    "    \n",
    "    #сохраняю таблицу с временем, заказами и вектором признаков\n",
    "#table_areas[6].write.parquet(f'area_1_hours/{i}_area.parquet');\n",
    "\n",
    "#df_train, df_validation, df_test = split(table_areas[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8636bfe7-a656-42e2-83f9-720f385b311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train, df_validation, df_test = split(table_areas[7])\n",
    "\n",
    "# Инициилизируем модель\n",
    "#задание параметров модели\n",
    "#предикт и таргет\n",
    "#label_col = 'count_1h'\n",
    "#prediction_col = 'pred_tree'\n",
    "#features = 'features_all'\n",
    "#оценка качества модели\n",
    "#mae_all_val = []\n",
    "#mae_all_test = []\n",
    "#mape_all_val = []\n",
    "#mape_all_test = []\n",
    "\n",
    "#models_lr = {}\n",
    "\n",
    "# Инициилизируем модель\n",
    "#tree = (DecisionTreeRegressor(featuresCol=features,\n",
    "#                              labelCol=label_col, \n",
    "#                              predictionCol=prediction_col, \n",
    "                              \n",
    "#                              maxBins=32,\n",
    "#                              maxDepth=10, \n",
    "#                              minInstancesPerNode=10))\n",
    "# Обучиаем модель на данных\n",
    "#models_tree = tree.fit(df_train)\n",
    "\n",
    "    #предсказание\n",
    "#df_validation = models_tree.transform(df_validation)\n",
    "    #MAE\n",
    "#evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "#mae_val = format(evaluator.evaluate(df_validation))\n",
    "#mae_all_val.append(float(mae_val))\n",
    "    #MAPE\n",
    "#result_val = mape(df_validation, label_col, prediction_col)\n",
    "#mape_all_val.append(result_val)\n",
    "\n",
    "#mae_all_val\n",
    "#mape_all_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a91e1a9-63c5-4ef7-ada3-9103201cd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #предсказание test\n",
    "#df_test = models_tree.transform(df_test)\n",
    "    #MAE\n",
    "#evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "#mae_test = format(evaluator.evaluate(df_test))\n",
    "#mae_all_test.append(float(mae_test))\n",
    "    #MAPE\n",
    "#result_test = mape(df_test, label_col, prediction_col)\n",
    "#mape_all_val.append(result_test)\n",
    "\n",
    "#mae_all_val\n",
    "#mape_all_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1c789-c62a-4db9-b60c-5b57b175208d",
   "metadata": {},
   "source": [
    "## Для всех районов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "635fc5b2-6012-4a2b-866d-35f3048e1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_validation, df_test = split(dikt)\n",
    "\n",
    "#задание параметров модели\n",
    "#предикт и таргет\n",
    "label_col = 'count_1h'\n",
    "prediction_col = 'pred_tree'\n",
    "features = 'features_all'\n",
    "\n",
    "#оценка качества модели\n",
    "mae_all_val = []\n",
    "mae_all_test = []\n",
    "\n",
    "mape_all_val = []\n",
    "mape_all_test = []\n",
    "\n",
    "models_tree = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5124841-a77b-4505-b95c-c97dcd0c5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициилизируем модель\n",
    "tree = (DecisionTreeRegressor(featuresCol=features,\n",
    "                              labelCol=label_col, \n",
    "                              predictionCol=prediction_col, \n",
    "                              \n",
    "                              maxBins=25,\n",
    "                              maxDepth=10, \n",
    "                              minInstancesPerNode=5\n",
    "                             ))\n",
    "# Обучиаем модели\n",
    "for i in range(1, 78):\n",
    "    \n",
    "    models_tree[i] = tree.fit(df_train[i])\n",
    "\n",
    "    #предсказание\n",
    "    df_validation[i] = models_tree[i].transform(df_validation[i])\n",
    "    #MAE\n",
    "    evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "    mae_val = format(evaluator.evaluate(df_validation[i]))\n",
    "    mae_all_val.append(float(mae_val))\n",
    "    #MAPE\n",
    "    result_val = mape(df_validation[i], label_col, prediction_col)\n",
    "    mape_all_val.append(result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7211503-64bd-4e64-94e9-7509e220bee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Среднее МАЕ по всем районам:', 2.310819470266529)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Среднее МАРЕ по всем районам:', 57.26886464778424)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Среднее МАЕ по всем районам:', sum(mae_all_val)/len(mae_all_val)\n",
    "'Среднее МАРЕ по всем районам:', sum(mape_all_val)/len(mape_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3a8f014-1572-4d2a-bab3-86d35c40bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#предсказание test \n",
    "for i in range(1, 78):\n",
    "     \n",
    "    df_test[i] = models_tree[i].transform(df_test[i])\n",
    "    #MAE\n",
    "    evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "    mae_test = format(evaluator.evaluate(df_test[i]))\n",
    "    mae_all_test.append(float(mae_test))\n",
    "    #MAPE\n",
    "    result_test = mape(df_test[i], label_col, prediction_col)\n",
    "    mape_all_test.append(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c85ee459-5167-4b5c-b67c-53d590e1bd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Среднее МАЕ по всем районам на тестостовой выборкуе:', 2.2638927524316474)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Среднее МАРЕ по всем районам на тестостовой выборкуе:', 58.814657460122625)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Среднее МАЕ по всем районам на тестостовой выборкуе:', sum(mae_all_test)/len(mae_all_test)\n",
    "'Среднее МАРЕ по всем районам на тестостовой выборкуе:', sum(mape_all_test)/len(mape_all_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6657b2-7e45-4f63-9289-cdffeb2134a6",
   "metadata": {},
   "source": [
    "**Вывод:** Можно сделать вывод что обученная модель не переобучилась и допускает ошибку для каждого района на 2 заказа, что достаточно неплохо. Если рассматривать в процентах, ошибка уже будет выглядеть более критично. Данную модель я буду использовать для предказания отдного часа лля каждого района. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06cbc4-75be-41ed-a7a5-f13ded67264c",
   "metadata": {},
   "source": [
    "# Проверка модели на тестовом дата сете\r\n",
    "Определенное колитов махинаций, а если быть точным не 1 десяток позволили нам ее привести к такому же типу, как и обучаемые данные.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a04bee05-a52d-4347-a4d0-93f3afc19ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tati_test = 'fails/y_true_2022-12-31_23-00_UTC0.csv'\n",
    "\n",
    "sdf_test = spark.read.csv(path=tati_test, header=True, inferSchema=True)\n",
    "sdf_test = sdf_test.withColumnRenamed(\"Pickup Community Area\", \"area\")\n",
    "sdf_test = sdf_test.withColumnRenamed(\"trips_count\", \"count_1h\")\n",
    "sdf_test = sdf_test.withColumnRenamed(\"hours\", \"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5aecbc3-3452-4fd8-9fd2-29110aa940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_format = \"MM/dd/yyyy hh:mm:ss a\"\n",
    "sdf_test = sdf_test.withColumn(\"datetime\", to_timestamp(\"datetime\", timestamp_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a46eec9f-5aa1-4998-b5a4-1bfbcba83a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#генерация признаков\n",
    "sdf_test = features_area(sdf_test, 4, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9a98309-4cff-47d6-a48c-3ec55549f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодирование временных признаков\n",
    "\n",
    "#Кодируем месяцы\n",
    "sdf_test = encode(sdf_test, 'month', 12);\n",
    "\n",
    "#Кодируем часы\n",
    "sdf_test = encode(sdf_test, 'hour', 24);\n",
    "\n",
    "#Кодируем дни\n",
    "sdf_test = encode(sdf_test, 'day', 31);\n",
    "\n",
    "#Кодируем день недели\n",
    "sdf_test = encode(sdf_test, 'day_week', 7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7437baf3-efeb-49e8-815c-1532a9ff70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_time_new = sdf_test.drop('area', 'datetime', 'count_1h', 'month',\n",
    "                                 'day', 'day_week', 'hour').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bb63754-4a9d-4878-b3ec-3280868f2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создание общего вектора фичей\n",
    "assembler = VectorAssembler(inputCols=feature_time_new, outputCol=\"features_all\")\n",
    "sdf_test = assembler.transform(sdf_test)\n",
    "\n",
    "sdf_test = sdf_test.select('area', 'datetime', \"count_1h\", \"features_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "721e4dc0-9cb5-4384-86a0-dbd472ca1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {}\n",
    "for q in range(1, 78):\n",
    "    area_dict[q] = sdf_test.filter(col('area') == q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5886af5-8dd1-44fa-8657-79ab8eeafdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+--------+--------------------+\n",
      "|area|           datetime|count_1h|        features_all|\n",
      "+----+-------------------+--------+--------------------+\n",
      "|  77|2022-12-31 23:00:00|       8|[0.0,0.0,0.0,0.0,...|\n",
      "+----+-------------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "area_dict[77].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d919534e-e5e0-4f5c-9286-da601cc7febc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_1_h = {}\n",
    "test_1_h_mae = []\n",
    "test_1_h_mape = []\n",
    "\n",
    "for i in range(1, 78):\n",
    "    area_dict[i] = models_tree[i].transform(area_dict[i])\n",
    "        \n",
    "        #MAE\n",
    "    evaluator = RegressionEvaluator(predictionCol=prediction_col, labelCol=label_col, metricName='mae')\n",
    "    mae_test = format(evaluator.evaluate(area_dict[i]))\n",
    "    test_1_h_mae.append(float(mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b6b165e-6a31-4942-94fd-d31c0424c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Среднее МАЕ для предсказания одного часа:', 7.365798046720732)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Среднее МАЕ для предсказания одного часа:', sum(test_1_h_mae)/len(test_1_h_mae)\n",
    "#'Среднее МАРЕ по всем районам на тестостовой выборкуе:', sum(mape_all_test)/len(mape_all_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f3a58-eef7-4e7e-a40d-7db11ab7c38f",
   "metadata": {},
   "source": [
    "**Вывод:** \n",
    "Результат для предсказания тестовой модели показал не очень радужные результаты. Думалось все будет лучше) \r\n",
    "Скорее всего это связано с тем, что лаги в данном временном диапазоне == 0. Но побороть эту проблему я не смог, думаю, что скрывается недочет именно тут.\r\n",
    "Параллельно пытался обучить ARIMA, она показала неплохой показатель на 1 районе, но пришлось перевести таблицу в формат pandas. Конечно, я хотел переписать ее на запросах от спарка, но оказалось это слишком сложно для меня поэтому от нее я отказался. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc7cb2-804b-4c4f-8d4e-78bc13144897",
   "metadata": {},
   "source": [
    "# **Общий вывод о проделанной работе:**\n",
    "Если мы дошли до этого момента, то код нигде не упал и все работает на костылях уже славно. Это мой девиз этого проекта)) \n",
    "\n",
    " 1.\tОбъединил 2 и рассматривал их как единый временный период.\n",
    "2.\tПровел предобработку данных, различными методами сгруппировал\n",
    "3.\tОтобразил графически сезонность спроса. \n",
    "4.\tОбучил модель Деревья решений и сделал предсказания со средней погрешностью 2.26 заказа. \n",
    "5.\tСделал тестовое предсказание 1 часа. Средняя погрешность составила 7.36 заказа по всем районам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5907d58-6804-4938-be2c-966ac771db67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
